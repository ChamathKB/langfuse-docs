{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "description: Langfuse Python SDK - a decorators-based integration to give you powerful tracing, evals, and analytics for your LLM application\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python SDK Guide\n",
    "\n",
    "[![PyPI](https://img.shields.io/pypi/v/langfuse?style=flat-square)](https://pypi.org/project/langfuse/)\n",
    "\n",
    "The Langfuse Python SDK uses decorators for you to effortlessly integrate observability into your LLM applications. It supports both synchronous and asynchronous functions, automatically handling traces, spans, and generations, along with key execution details like inputs and outputs. This setup allows you to concentrate on developing high-quality applications while benefitting from observability insights with minimal code.\n",
    "\n",
    "If you use [Langchain](/docs/integrations/langchain), [LlamaIndex](/docs/integrations/llama-index) or other popular frameworks to build your LLM app, check out our [integrations](/docs/integrations) for tailored solutions.\n",
    "\n",
    "For a detailed API reference, see our [Python SDK API Reference](https://f5cb2b86.langfuse-python.pages.dev/langfuse/decorators/langfuse#LangfuseDecorator).\n",
    "\n",
    "Here's a simple example of our decorators-based Python SDK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse\n",
    "\n",
    "\n",
    "@langfuse.trace()\n",
    "def span_inside_trace():\n",
    "    print(\"Hello, from a span inside a trace!\")\n",
    "\n",
    "\n",
    "@langfuse.trace()\n",
    "def function_to_trace():\n",
    "    print(\"Hello, from the parent trace!\")\n",
    "    span_inside_trace()\n",
    "\n",
    "\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VoilÃ ! âœ¨ Langfuse will generate a trace with a nested span for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation & setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install `langfuse`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you haven't done so yet, [sign up to Langfuse](https://cloud.langfuse.com/auth/sign-up) and obtain your API keys from the project settings. Configure your environment variables to reflect the correct values for `LANGFUSE_HOST`, `LANGFUSE_SECRET_KEY`, and `LANGFUSE_PUBLIC_KEY`. You can use either a `.env` file at the root of your application in combination with `python-dotenv`, or set them directly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# .env\n",
    "LANGFUSE_SECRET_KEY=\"sk-lf-...\";\n",
    "LANGFUSE_PUBLIC_KEY=\"pk-lf-...\";\n",
    "LANGFUSE_HOST=\"https://cloud.langfuse.com\"; # ðŸ‡ªðŸ‡º EU region, \"https://us.cloud.langfuse.com\" for ðŸ‡ºðŸ‡¸ US region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = (\n",
    "    \"https://cloud.langfuse.com\"  # ðŸ‡ªðŸ‡º EU region, \"https://us.cloud.langfuse.com\" for ðŸ‡ºðŸ‡¸ US region\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langfuse simplifies observability in LLM-powered applications by organizing activities into traces. Each trace contains observations: spans for nested activities, events for distinct actions, or generations for LLM interactions. This setup mirrors your app's execution flow, offering insights into performance and behavior. See our [Tracing documentation](/docs/tracing/overview) for more details on Langfuse's telemetry model.\n",
    "\n",
    "Langfuse simplifies application tracing with the `@langfuse.trace()` decorator, automating the tracking of execution times and the nesting hierarchy of calls. This approach allows you to seamlessly integrate observability by simply decorating the functions you'd like to trace, and focusing on feature development while Langfuse handles the intricacies of contexts and nested calls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture traces\n",
    "\n",
    "In Langfuse, traces serve as the foundational element, acting as containers for various observations within your application. Traces are capable of representing comprehensive execution flows, such as those found in chained LLM applications, backend endpoint processes, or any complex sequence involving multiple observations. This hierarchical structure allows for a detailed and organized view of application performance and behavior.\n",
    "\n",
    "Utilizing the `@langfuse.trace()` decorator provided by the Langfuse Python SDK, you can designate the top-level function in a sequence as a trace. Subsequent nested function calls decorated with `@langfuse.trace()` are automatically recognized as either spans, which are subdivisions of a trace capturing specific operations, or generations, which are specialized observations for LLM interactions.\n",
    "\n",
    "Here's a concise example demonstrating how to employ the Langfuse decorator to capture traces, spans, and generations, and how to finalize the trace by flushing it to the Langfuse platform for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse\n",
    "\n",
    "\n",
    "@langfuse.trace(as_type=\"generation\")\n",
    "def deeply_nested_llm_call():\n",
    "    # Logic for a deeply nested LLM call\n",
    "    pass\n",
    "\n",
    "\n",
    "@langfuse.trace()\n",
    "def nested_span():\n",
    "    # This creates a new span within the trace\n",
    "    deeply_nested_llm_call()\n",
    "\n",
    "\n",
    "@langfuse.trace()\n",
    "def main():\n",
    "    # The entry point creating a new trace\n",
    "    nested_span()\n",
    "\n",
    "\n",
    "# Execute the main function to initiate the trace\n",
    "main()\n",
    "\n",
    "# Flush the collected data to the Langfuse platform\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the resulting hierarchy from the above executions:\n",
    "\n",
    "![python_decorators_nesting](/public/images/cookbook/python_decorators_nesting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enrich elements\n",
    "\n",
    "Enhancing the detail and relevance of your observability data in Langfuse is straightforward. By leveraging the `langfuse.update_current_observation` and `langfuse.update_current_trace` methods, you can enrich the context of your observability data directly within the scope of the function being observed.\n",
    "\n",
    "When adding parameters, consider the specific observation type that is in context. The [Python SDK API Reference](https://f5cb2b86.langfuse-python.pages.dev/langfuse/decorators/langfuse#LangfuseDecorator.update_current_observation) provides a comprehensive list of the parameters you can set per observation type. Trace parameters can be updated from any point within the nested function hierarchy.\n",
    "\n",
    "Below is an example demonstrating how to enrich traces and observations with custom parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse\n",
    "\n",
    "\n",
    "@langfuse.trace(as_type=\"generation\")\n",
    "def deeply_nested_llm_call():\n",
    "    # Enrich the current observation with a custom name, input, and output\n",
    "    langfuse.update_current_observation(\n",
    "        name=\"Deeply nested LLM call\", input=\"Ping?\", output=\"Pong!\"\n",
    "    )\n",
    "    # Set the parent trace's name from within a nested observation\n",
    "    langfuse.update_current_trace(\n",
    "        name=\"Trace name set from deeply_nested_llm_call\",\n",
    "        session_id=\"1234\",\n",
    "        user_id=\"5678\",\n",
    "        tags=[\"tag1\", \"tag2\"],\n",
    "    )\n",
    "\n",
    "\n",
    "@langfuse.trace()\n",
    "def nested_span():\n",
    "    # Update the current span with a custom name and level\n",
    "    langfuse.update_current_observation(name=\"Nested Span\", level=\"WARNING\")\n",
    "    deeply_nested_llm_call()\n",
    "\n",
    "\n",
    "@langfuse.trace()\n",
    "def main():\n",
    "    nested_span()\n",
    "\n",
    "\n",
    "# Execute the main function to generate the enriched trace\n",
    "main()\n",
    "\n",
    "# Flush the enriched data to the Langfuse platform for analysis\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the Langfuse platform the trace now shows with the updated name from the `deeply_nested_llm_call`, and the observations will be enriched with the appropriate data points.\n",
    "\n",
    "![python_decorators_enriched-nesting](/public/images/cookbook/python_decorators_enriched-nesting.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flush observations\n",
    "\n",
    "The Langfuse SDK executes network requests in the background on a separate thread for better performance of your application. This can lead to lost events in short lived environments such as AWS Lambda functions when the Python process is terminated before the SDK sent all events to our backend.\n",
    "\n",
    "To avoid this, ensure that the `langfuse.flush()` method is called before termination. This method is waiting for all tasks to have completed, hence it is blocking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [WIP - not ready for review]Scoring\n",
    "\n",
    "[Scores](https://langfuse.com/docs/scores/overview) are used to evaluate single observations or entire traces. They can created manually via the Langfuse UI or via the SDKs.\n",
    "\n",
    "If the score relates to a specific step of the trace, specify the `observation_id`.\n",
    "\n",
    "| Parameter | Type   | Optional | Description\n",
    "| --- | --- | --- | ---\n",
    "| trace_id | string | no | The id of the trace to which the score should be attached. Automatically set if you use `{trace,generation,span,event}.score({})`\n",
    "| observation_id | string | yes | The id of the observation to which the score should be attached. Automatically set if you use `{generation,span,event}.score({})`\n",
    "| name | string | no | Identifier of the score.\n",
    "| value | number | no | The value of the score. Can be any number, often standardized to 0..1\n",
    "| comment | string | yes | Additional context/explanation of the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse\n",
    "\n",
    "\n",
    "# This will create a new span under the trace\n",
    "@langfuse.trace()\n",
    "def nested_span():\n",
    "    langfuse.score_current_observation(\n",
    "        name=\"feedback-on-span\",\n",
    "        value=1,\n",
    "        comment=\"I like how personalized the response is\",\n",
    "    )\n",
    "\n",
    "    langfuse.score_current_trace(\n",
    "        name=\"feedback-on-trace\",\n",
    "        value=1,\n",
    "        comment=\"I like how personalized the response is\",\n",
    "    )\n",
    "\n",
    "\n",
    "# This will create a new trace\n",
    "@langfuse.trace()\n",
    "def main():\n",
    "    nested_span()\n",
    "\n",
    "\n",
    "main()\n",
    "\n",
    "# Flush the trace to send it to the Langfuse platform\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom IDs\n",
    "\n",
    "If you have your own unique ID representing an execution (messageId, traceId, correlationId), you can easily set those as trace or observation IDs for effective lookups in Langfuse. To set a custom ID for a trace or observation, simply pass the `langfuse_observation_id` as a keyword argument *within the traced function*. Requiring `langfuse_observation_id` to be set as a keyword argument (kwarg) here rather than as a static decorator argument enables ID assignment at runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.decorators import langfuse\n",
    "\n",
    "\n",
    "@langfuse.trace()\n",
    "def process_user_request(user_id, request_data, **kwargs):\n",
    "    # Function logic here\n",
    "    pass\n",
    "\n",
    "\n",
    "def main():\n",
    "    user_id = \"user123\"\n",
    "    request_data = {\"action\": \"login\"}\n",
    "\n",
    "    # Custom ID for tracking\n",
    "    custom_observation_id = f\"{user_id}-{request_data['action']}\"\n",
    "    process_user_request(\n",
    "        user_id=user_id,\n",
    "        request_data=request_data,\n",
    "        langfuse_observation_id=custom_observation_id,\n",
    "    )\n",
    "\n",
    "\n",
    "main()\n",
    "\n",
    "# Flush the trace to send it to the Langfuse platform\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug mode\n",
    "Enable debug mode to get verbose logs. Set the debug mode via the environment variable `LANGFUSE_DEBUG=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication check\n",
    "\n",
    "Use `langfuse.auth_check()` to verify that your host and API credentials are valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Releases and versions\n",
    "\n",
    "Track `releases` in Langfuse to relate traces in Langfuse with the versioning of your application. This can be done by setting the environment variable `LANGFUSE_RELEASE` or setting it as a trace parameter.\n",
    "\n",
    "If no release is set, this defaults to [common system environment names](https://github.com/langfuse/langfuse-python/blob/main/langfuse/environment.py#L3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "See the [Python SDK API reference](https://f5cb2b86.langfuse-python.pages.dev/langfuse/decorators/langfuse#LangfuseDecorator) for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langfuse-wN49ODZY-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
