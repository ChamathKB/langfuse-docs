{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlceIPalN3QR"
      },
      "source": [
        "---\n",
        "description: Example of Open Source Prompt Management for LlamaIndex applications using Langfuse.\n",
        "\n",
        "category: Prompt Management\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqBspBzuRk9C"
      },
      "source": [
        "Example: Langfuse Prompt Management with LlamaIndex (Python)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1oaA7XYGOfX"
      },
      "source": [
        "[Langfuse Prompt Management](https://langfuse.com/docs/prompts) helps to version control and manage prompts collaboratively in one place. This example demostrates how to use prompts managed in LlamaIndex applications.\n",
        "\n",
        "_In addition, we use [Langfuse Tracing](https://langfuse.com/docs/tracing) via the native [LlamaIndex integration](https://langfuse.com/docs/integrations/llama-index) to inspect and debug the LlamaIndex application._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbSpd5EiZouE"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNyU6IzCZouE"
      },
      "outputs": [],
      "source": [
        "%pip install langfuse llama_index --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpE57ujJZouE"
      },
      "source": [
        "Initialize the Langfuse client with your API keys from the project settings in the Langfuse UI and add them to your environment. Also register Langfuse's `LlamaIndexCallbackHandler` in the LLamaIndex settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEdF-668ZouF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# get keys for your project from https://cloud.langfuse.com\n",
        "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-***\"\n",
        "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-***\"\n",
        "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\" # for EU data region\n",
        "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # for US data region\n",
        "\n",
        "# your openai key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"***\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core.callbacks import CallbackManager\n",
        "from langfuse.llama_index import LlamaIndexCallbackHandler\n",
        "\n",
        "# Initialize Langfuse client (prompt management)\n",
        "langfuse = Langfuse()\n",
        "\n",
        "langfuse_callback_handler = LlamaIndexCallbackHandler() # get langfuse's llamaindex callback handler\n",
        "Settings.callback_manager = CallbackManager([langfuse_callback_handler]) # register callback handler in settings"
      ],
      "metadata": {
        "id": "CGPGDdv7Iy8I"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdHpmb6vLAiW"
      },
      "source": [
        "## Add prompt to Langfuse Prompt Management\n",
        "\n",
        "We add the prompt used in this example via the SDK. Alternatively, you can also edit and version the prompt in the Langfuse UI.\n",
        "\n",
        "- `Name` that identifies the prompt in Langfuse Prompt Management\n",
        "- Prompt with prompt template incl. `{{input variables}}`\n",
        "- Config including `model_name` and `temperature`\n",
        "- `is_active` to immediately use prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "pX54t3k0gM5w"
      },
      "outputs": [],
      "source": [
        "langfuse.create_prompt(\n",
        "    name=\"event-planner\",\n",
        "    prompt=\n",
        "    \"Plan an event titled {{event_name}}. The event will be about: {{event_description}}. \"\n",
        "    \"The event will be held in {{location}} on {{date}}. \"\n",
        "    \"Consider the following factors: audience, budget, venue, catering options, and entertainment. \"\n",
        "    \"Provide a detailed plan including potential vendors and logistics.\",\n",
        "    config={\n",
        "        \"model\":\"gpt-3.5-turbo-1106\",\n",
        "        \"temperature\": 0,\n",
        "    },\n",
        "    is_active=True\n",
        ");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euww_r78IjtC"
      },
      "source": [
        "Prompt in Langfuse UI\n",
        "\n",
        "![Created prompt in Langfuse UI](https://langfuse.com/images/docs/prompt-management-langchain-prompt.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1IZ9UWUIjtC"
      },
      "source": [
        "## Example application\n",
        "\n",
        "### Get current prompt version from Langfuse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0nYuMLzIJeb",
        "outputId": "fd8c7737-0706-40c2-d395-81a6f2a1ada4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plan an event titled {{event_name}}. The event will be about: {{event_description}}. The event will be held in {{location}} on {{date}}. Consider the following factors: audience, budget, venue, catering options, and entertainment. Provide a detailed plan including potential vendors and logistics.\n"
          ]
        }
      ],
      "source": [
        "# Get current production version of prompt\n",
        "langfuse_prompt = langfuse.get_prompt(\"event-planner\")\n",
        "print(langfuse_prompt.prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahvMYvS1RsF9"
      },
      "source": [
        "### Transform into LlamaIndex PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQwfPI42IZM0"
      },
      "source": [
        "Use the utility method `.get_langchain_prompt()` to transform the Langfuse prompt into a string that can be used in LlamaIndex.\n",
        "\n",
        "Context: Langfuse declares input variables in prompt templates using double brackets (`{{input variable}}`). LlamaIndex uses single brackets for declaring input variables in PromptTemplates (`{input variable}`). The utility method `.get_langchain_prompt()` replaces the double brackets with single brackets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "W0PHfX_QMWHM"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import PromptTemplate\n",
        "\n",
        "llama_index_prompt = PromptTemplate(langfuse_prompt.get_langchain_prompt())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZWWnEVyN9AK"
      },
      "source": [
        "Extract the configuration options from `prompt.config`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4FNbRwROCab",
        "outputId": "b1f21d93-5a59-4b4e-c401-6fa1053d2216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt model configurations\n",
            "Model: gpt-3.5-turbo-1106\n",
            "Temperature: 0\n"
          ]
        }
      ],
      "source": [
        "model = langfuse_prompt.config[\"model\"]\n",
        "temperature = str(langfuse_prompt.config[\"temperature\"])\n",
        "print(f\"Prompt model configurations\\nModel: {model}\\nTemperature: {temperature}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGCZnwK4CI31"
      },
      "source": [
        "### Format prompt and define LlamaIndex chat engine\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Phi3qcusC0Aa"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.chat_engine import SimpleChatEngine\n",
        "\n",
        "prompt = llama_index_prompt.format(\n",
        "    event_name = \"Wedding\",\n",
        "    event_description = \"The wedding of Julia and Alex, a charming couple who share a love for art and nature. This special day will celebrate their journey together with a blend of traditional and contemporary elements, reflecting their unique personalities.\",\n",
        "    location = \"Central Park, New York City\",\n",
        "    date = \"June 5, 2024\"\n",
        ")\n",
        "\n",
        "chat_engine = SimpleChatEngine.from_defaults()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEzzzavik9g8"
      },
      "source": [
        "## Invoke chat engine"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat_engine.chat(prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5sMvxReZXEL",
        "outputId": "01c66758-5f89-495a-dd65-c7342461cea8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Event Title: Wedding of Julia and Alex\n",
            "\n",
            "Date: June 5, 2024\n",
            "Venue: Central Park, New York City\n",
            "Audience: Family and friends of Julia and Alex\n",
            "Budget: $20,000\n",
            "\n",
            "Event Plan:\n",
            "\n",
            "1. Venue:\n",
            "Central Park offers a beautiful and natural setting for the wedding ceremony. The couple will exchange vows in the Shakespeare Garden, surrounded by lush greenery and blooming flowers. The reception will take place at the Loeb Boathouse, overlooking the lake.\n",
            "\n",
            "2. Catering:\n",
            "For catering, we will hire a local catering company that specializes in farm-to-table cuisine. The menu will feature seasonal dishes made with fresh, locally sourced ingredients. Options will include a variety of appetizers, entrees, and desserts to suit all dietary preferences.\n",
            "\n",
            "3. Entertainment:\n",
            "To entertain guests during the reception, we will hire a live band that can play a mix of classic love songs and contemporary hits. Additionally, we will have a DJ to keep the party going late into the night. The couple will also have a photo booth set up for guests to capture fun memories.\n",
            "\n",
            "4. Decor:\n",
            "The decor will reflect the couple's love for art and nature. We will use a color palette of soft pastels and earth tones, with floral arrangements featuring wildflowers and greenery. The tables will be adorned with artistic centerpieces and handmade place cards.\n",
            "\n",
            "5. Logistics:\n",
            "- Transportation: Shuttle buses will be arranged to transport guests from the ceremony to the reception venue.\n",
            "- Seating: A seating chart will be created to ensure that guests are seated with their desired companions.\n",
            "- Timeline: A detailed timeline will be established to ensure that all events run smoothly and on schedule.\n",
            "- Photography: A professional photographer will be hired to capture all the special moments of the day.\n",
            "\n",
            "Potential Vendors:\n",
            "- Catering: Farm-to-Table Catering Co.\n",
            "- Entertainment: Love Notes Band, DJ Party Time\n",
            "- Decor: Artistic Blooms Floral Design\n",
            "- Photography: Capture the Moment Photography\n",
            "\n",
            "Overall, the wedding of Julia and Alex will be a magical and memorable event that celebrates their love and unique personalities. The blend of traditional and contemporary elements, along with the beautiful setting of Central Park, will create a truly special day for the couple and their guests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQlOxtZGhKN7"
      },
      "source": [
        "## View Trace in Langfuse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFBmiR-agkb7"
      },
      "source": [
        "Now we can see that the trace incl. the prompt template have been logged to Langfuse\n",
        "\n",
        "Todo: Replace screenshot (https://cloud.langfuse.com/project/clr4qu8qv0000yu4ja339x02u/traces/a815e715-7234-4b19-b792-2f1f0d5c1a10)\n",
        "\n",
        "![Trace of prompt used in Langchain in Langfuse](https://langfuse.com/images/docs/prompt-management-langchain-trace.png)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}